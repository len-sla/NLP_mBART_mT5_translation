{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NTLK_spliting by sentence_original_txt.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOCgJt/ytMyWLK2+CAluwee"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rhRR8xd4j5po"},"source":["# Preparing text files for Marian transformer translator\r\n","## there are some problems with using in the same notebook Marian translator and NTLK  ( looks like NTLK using old method of seg2seq)"]},{"cell_type":"markdown","metadata":{"id":"wDo-Ixn1hUk5"},"source":["# 1. Mounting google drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mikC8BT8fyA_","executionInfo":{"status":"ok","timestamp":1612199503454,"user_tz":-60,"elapsed":23439,"user":{"displayName":"Marek Leszczynski","photoUrl":"","userId":"05664549655810509768"}},"outputId":"71c9a2ef-992c-4680-c8e8-af971c46b8c8"},"source":["#Mount Google Drive as folder\r\n","from google.colab import drive\r\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5xpOhcRdgE2i","executionInfo":{"status":"ok","timestamp":1612209242763,"user_tz":-60,"elapsed":1233,"user":{"displayName":"Marek Leszczynski","photoUrl":"","userId":"05664549655810509768"}},"outputId":"3c129678-e025-452e-b745-2f706a521f88"},"source":["from IPython.display import HTML\r\n","from IPython.display import Image\r\n","from tqdm import tqdm\r\n","import nltk.data\r\n","nltk.download('punkt')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"Vfc8FXSlfI6K"},"source":["# 2. Read german text to list, remove original \\n line spliting  split by sentence and save as text file spliting by sentence using ntlk"]},{"cell_type":"code","metadata":{"id":"REHH3A55kzir"},"source":["# tokenizer = nltk.data.load('tokenizers/punkt/english.pickle') #if it will be english text\r\n","# tokenizer = nltk.data.load('tokenizers/punkt/german.pickle') #if it will be german text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"48NEWKUlMK5l"},"source":["there was need to solve the  problem with utf-8"]},{"cell_type":"code","metadata":{"id":"q7Vpos3ILmaR","executionInfo":{"status":"ok","timestamp":1612209706457,"user_tz":-60,"elapsed":754,"user":{"displayName":"Marek Leszczynski","photoUrl":"","userId":"05664549655810509768"}}},"source":["# reading text file to list and removing original \\n end of line signs\r\n","def read_file_to_list_remove_end(file_name): \r\n","    lines = []\r\n","    with open(file_name, encoding=\"utf8\", errors='ignore') as f:\r\n","        for line in f.readlines():\r\n","            line = line.replace(\"\\n\", \" \")\r\n","            if line:\r\n","                lines.append(line)\r\n","                \r\n","    return \"\".join(lines)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NEJlix-ypSIW","executionInfo":{"status":"ok","timestamp":1612209712090,"user_tz":-60,"elapsed":762,"user":{"displayName":"Marek Leszczynski","photoUrl":"","userId":"05664549655810509768"}},"outputId":"87ca8b0d-e82a-4ccf-8f61-ab86cc645552"},"source":["#@title (GERMAN nltk )Realign \"\\n\" to end of  sentences , save result { display-mode: \"form\" }\r\n","\r\n","text_file = \"/content/drive/MyDrive/trans_pl/kapitel_68.txt\" #@param [\"\"] {allow-input: true}\r\n","\r\n","file_name= text_file\r\n","lines= read_file_to_list_remove_end(file_name)\r\n","print('1. temp  list was created from file  it is {} lines  long '.format(len(lines)))\r\n","\r\n","# ===================placing end of lines after sentences\r\n","tokenizer = nltk.data.load('tokenizers/punkt/german.pickle')\r\n","text_temp='\\n'.join(tokenizer.tokenize(lines, realign_boundaries=True))\r\n","\r\n","\r\n","output_text_file= text_file[:-4]+'_relined.txt'\r\n","\r\n","#writing list to file attaching after every list item end of line sign \\n\r\n","with open(output_text_file, 'w') as output:\r\n","    for row in text_temp:\r\n","        output.write(str(row))\r\n","print('Religned file {} was saved'.format(output_text_file))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["1. temp  list was created from file  it is 91055 lines  long \n","Religned file /content/drive/MyDrive/trans_pl/kapitel_68_relined.txt was saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u2lzqdGgkjbP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2aYUITlrW7Z"},"source":["#@title (ENGLISH nltk )Realign \"\\n\" to end of  sentences , save result { display-mode: \"form\" }\r\n","\r\n","text_file = \"/content/drive/MyDrive/trans_pl/kapitel_68.txt\" #@param [\"\"] {allow-input: true}\r\n","\r\n","file_name= text_file\r\n","lines= read_file_to_list_remove_end(file_name)\r\n","print('1. temp  list was created from file  it is {} lines  long '.format(len(lines)))\r\n","\r\n","# ===================placing end of lines after sentences\r\n","tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\r\n","text_temp='\\n'.join(tokenizer.tokenize(lines, realign_boundaries=True))\r\n","# print('2. converted   list was created from file  it is {} lines  long '.format(len(text_temp)))\r\n","\r\n","output_text_file= text_file[:-4]+'_relined.txt'\r\n","\r\n","#writing list to file attaching after every list item end of line sign \\n\r\n","with open(output_text_file, 'w') as output:\r\n","    for row in text_temp:\r\n","        output.write(str(row))\r\n","print('Religned file {} was saved'.format(output_text_file))"],"execution_count":null,"outputs":[]}]}